{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d5becf7b-3234-4e99-8474-079bc5f652bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e23664f-3311-43ae-bc13-e10676172dea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'positive', 'score': 0.9461501836776733}]\n"
     ]
    }
   ],
   "source": [
    "model_name = \"r1char9/rubert-base-cased-russian-sentiment\"\n",
    "\n",
    "classifier = pipeline(\"sentiment-analysis\", model=model_name)\n",
    "\n",
    "text = \"Video is okay! I think its pretty good!\"\n",
    "\n",
    "result = classifier(text)\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e40d030-54e7-4b9c-8100-c9842f4b594c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Загрузка моделей... Это может занять несколько минут.\n",
      "Все рабочие модели успешно загружены!\n",
      "\n",
      "--- Тестирование аналитического конвейера ---\n",
      "\n",
      "Анализ комментария 1: {'text': 'Отличный сервис, скорость интернета просто летает! Спасибо!', 'language': 'ru', 'toxicity': 'non-toxic', 'sentiment': 'positive'}\n",
      "Анализ комментария 2: {'text': 'Что за отвратительная связь, вы надоели уже со своими обещаниями!', 'language': 'ru', 'toxicity': 'non-toxic', 'sentiment': 'negative'}\n",
      "Анализ комментария 3: {'text': 'Керемет! Маған бәрі ұнады, рахмет сіздерге.', 'language': 'tr', 'toxicity': 'N/A', 'sentiment': 'N/A'}\n",
      "Анализ комментария 4: {'text': 'This is a great service, thank you!', 'language': 'en', 'toxicity': 'N/A', 'sentiment': 'N/A'}\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "language_detector = pipeline('text-classification', model='papluca/xlm-roberta-base-language-detection')\n",
    "\n",
    "rus_toxicity_classifier = pipeline('text-classification', model='cointegrated/rubert-tiny-toxicity')\n",
    "\n",
    "rus_sentiment_classifier = pipeline('sentiment-analysis', model='r1char9/rubert-base-cased-russian-sentiment')\n",
    "\n",
    "# multi_toxicity_classifier = pipeline('text-classification', model='s-nlp/xlmr_formality_toxic_multilingual')\n",
    "\n",
    "multi_sentiment_classifier = pipeline('sentiment-analysis', model='tabularisai/multilingual-sentiment-analysis')\n",
    "\n",
    "print(\"All the models succesfully loaded!\")\n",
    "\n",
    "\n",
    "\n",
    "def analyze_comment(comment_text: str) -> dict:\n",
    "    \n",
    "    lang_result = language_detector(comment_text, top_k=1)\n",
    "    language = lang_result[0]['label']\n",
    "    \n",
    "    toxicity = \"N/A\"  \n",
    "    sentiment = \"N/A\"\n",
    "\n",
    "    if language == 'ru':\n",
    "        toxicity_result = rus_toxicity_classifier(comment_text)\n",
    "        toxicity = toxicity_result[0]['label']\n",
    "\n",
    "        sentiment_result = rus_sentiment_classifier(comment_text)\n",
    "        sentiment = sentiment_result[0]['label']\n",
    "\n",
    "    elif language == 'kk': \n",
    "        # toxicity_result = multi_toxicity_classifier(comment_text)\n",
    "        # toxicity = toxicity_result[0]['label']\n",
    "        \n",
    "        sentiment_result = multi_sentiment_classifier(comment_text)\n",
    "        sentiment = sentiment_result[0]['label']\n",
    "    \n",
    "    final_analysis = {\n",
    "        'text': comment_text,\n",
    "        'language': language,\n",
    "        'toxicity': toxicity,\n",
    "        'sentiment': sentiment\n",
    "    }\n",
    "    \n",
    "    return final_analysis\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    test_comment_ru_ok = \"Отличный сервис, скорость интернета просто летает! Спасибо!\"\n",
    "    test_comment_ru_toxic = \"Что за отвратительная связь, вы надоели уже со своими обещаниями!\"\n",
    "    test_comment_kz = \"Керемет! Маған бәрі ұнады, рахмет сіздерге.\"\n",
    "    test_comment_en = \"This is a great service, thank you!\"\n",
    "    \n",
    "    print(\"\\n--- Testing: ... ---\")\n",
    "    \n",
    "    analysis1 = analyze_comment(test_comment_ru_ok)\n",
    "    print(f\"\\nАнализ комментария 1: {analysis1}\")\n",
    "\n",
    "    analysis2 = analyze_comment(test_comment_ru_toxic)\n",
    "    print(f\"Анализ комментария 2: {analysis2}\")\n",
    "    \n",
    "    analysis3 = analyze_comment(test_comment_kz)\n",
    "    print(f\"Анализ комментария 3: {analysis3}\")\n",
    "\n",
    "    analysis4 = analyze_comment(test_comment_en)\n",
    "    print(f\"Анализ комментария 4: {analysis4}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf4ae9de-1b06-4fea-b6aa-599bc4e0d45a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langdetect in c:\\users\\aidal\\anaconda3\\envs\\dsfs\\lib\\site-packages (1.0.9)\n",
      "Requirement already satisfied: six in c:\\users\\aidal\\anaconda3\\envs\\dsfs\\lib\\site-packages (from langdetect) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install langdetect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "79ac1b50-408e-40a5-9842-f7b625575ccd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Загрузка моделей... Это может занять несколько минут.\n",
      "Все рабочие модели успешно загружены!\n",
      "\n",
      "--- Тестирование финального аналитического конвейера ---\n",
      "\n",
      "Вопрос: {'text': 'Подскажите, как сменить тариф?', 'language': 'ru', 'moderation_verdict': 'ok', 'sentiment': 'neutral', 'comment_type': 'feedback'}\n",
      "Благодарность: {'text': 'Спасибо вам большое, все отлично работает!', 'language': 'ru', 'moderation_verdict': 'ok', 'sentiment': 'positive', 'comment_type': 'gratitude'}\n",
      "Жалоба: {'text': 'Ужасный интернет, постоянно пропадает!', 'language': 'ru', 'moderation_verdict': 'ok', 'sentiment': 'negative', 'comment_type': 'feedback'}\n",
      "Отзыв: {'text': 'Пользуюсь уже год, в целом нормально.', 'language': 'ru', 'moderation_verdict': 'ok', 'sentiment': 'positive', 'comment_type': 'feedback'}\n",
      "Спам: {'text': 'Заходи на мой канал про крипту www.example.com', 'language': 'ru', 'moderation_verdict': 'spam', 'sentiment': 'N/A', 'comment_type': 'N/A'}\n",
      "Ошибка перевода: 'NllbTokenizerFast' object has no attribute 'get_lang_id'\n",
      "Казахский: {'text': 'Керемет! Маған бәрі ұнады, рахмет сіздерге.', 'language': 'kk', 'moderation_verdict': 'ok', 'sentiment': 'neutral', 'comment_type': 'feedback'}\n",
      "Русский: {'text': 'Почему интернет так тупит?', 'language': 'ru', 'moderation_verdict': 'ok', 'sentiment': 'neutral', 'comment_type': 'feedback'}\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, pipeline\n",
    "\n",
    "print(\"Загрузка моделей... Это может занять несколько минут.\")\n",
    "\n",
    "language_detector = pipeline('text-classification', model='papluca/xlm-roberta-base-language-detection')\n",
    "\n",
    "translator_tokenizer = AutoTokenizer.from_pretrained(\"facebook/nllb-200-distilled-600M\")\n",
    "translator_model = AutoModelForSeq2SeqLM.from_pretrained(\"facebook/nllb-200-distilled-600M\")\n",
    "\n",
    "rus_toxicity_classifier = pipeline('text-classification', model='cointegrated/rubert-tiny-toxicity')\n",
    "rus_sentiment_classifier = pipeline('sentiment-analysis', model='r1char9/rubert-base-cased-russian-sentiment')\n",
    "\n",
    "en_toxicity_classifier = pipeline('text-classification', model='martin-ha/toxic-comment-model')\n",
    "en_sentiment_classifier = pipeline('sentiment-analysis', model='distilbert-base-uncased-finetuned-sst-2-english')\n",
    "\n",
    "zero_shot_classifier = pipeline(\"zero-shot-classification\", model=\"MoritzLaurer/mDeBERTa-v3-base-mnli-xnli\")\n",
    "\n",
    "print(\"All models succesfully loaded!\")\n",
    "\n",
    "SPAM_MARKERS = {\"подпис\", \"канал\", \"заход\", \"переход\", \"профил\", \"ссылк\", \"заработ\", \"крипт\"}\n",
    "URL_PATTERN = re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "\n",
    "\n",
    "def clean_text(text: str) -> str:\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    return \" \".join(text.split())\n",
    "\n",
    "def is_kazakh(text: str) -> bool:\n",
    "    KAZAKH_CHARS = set(\"ӘәҒғҚқҢңӨөҰұҮүҺһІі\")\n",
    "    return any(char in KAZAKH_CHARS for char in text)\n",
    "\n",
    "def translate_to_russian(text: str, src_lang_code: str = \"kaz_Cyrl\") -> str:\n",
    "    try:\n",
    "        translator_tokenizer.src_lang = src_lang_code\n",
    "        encoded_text = translator_tokenizer(text, return_tensors=\"pt\")\n",
    "        target_lang_id = translator_tokenizer.get_lang_id(\"rus_Cyrl\")\n",
    "        generated_tokens = translator_model.generate(**encoded_text, forced_bos_token_id=target_lang_id)\n",
    "        return translator_tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)[0]\n",
    "    except Exception as e:\n",
    "        print(f\"Translation error: {e}\")\n",
    "        return text\n",
    "\n",
    "def detect_spam_by_rules(text: str) -> bool:\n",
    "    text_lower = text.lower()\n",
    "    if URL_PATTERN.search(text_lower):\n",
    "        return True\n",
    "    if any(marker in text_lower for marker in SPAM_MARKERS):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def get_moderation_verdict(text: str, language: str) -> str:\n",
    "    if detect_spam_by_rules(text):\n",
    "        return 'spam'\n",
    "    \n",
    "    toxicity_result = 'non-toxic'\n",
    "    if language in ['ru', 'kk']:\n",
    "        toxicity_result = rus_toxicity_classifier(text)[0]['label']\n",
    "    elif language == 'en':\n",
    "        toxicity_result = en_toxicity_classifier(text)[0]['label']\n",
    "    \n",
    "    return 'insult' if toxicity_result == 'toxic' else 'ok'\n",
    "\n",
    "\n",
    "\n",
    "def analyze_comment(comment_text: str) -> dict:\n",
    "    \n",
    "    cleaned_text = clean_text(comment_text)\n",
    "    if not cleaned_text:\n",
    "        return {\n",
    "            'text': comment_text, 'language': 'unknown', 'moderation_verdict': 'ok',\n",
    "            'sentiment': 'N/A', 'comment_type': 'N/A'\n",
    "        }\n",
    "\n",
    "    if is_kazakh(cleaned_text):\n",
    "        detected_language = 'kk'\n",
    "    else:\n",
    "        lang_results = language_detector(cleaned_text, top_k=1)\n",
    "        detected_language = lang_results[0]['label']\n",
    "            \n",
    "    sentiment = \"N/A\"\n",
    "    comment_type = \"N/A\"\n",
    "    text_to_analyze = cleaned_text\n",
    "    \n",
    "    if detected_language == 'kk':\n",
    "        text_to_analyze = translate_to_russian(cleaned_text, src_lang_code=\"kaz_Cyrl\")\n",
    "\n",
    "    moderation_verdict = get_moderation_verdict(text_to_analyze, detected_language)\n",
    "\n",
    "    if moderation_verdict != 'spam':\n",
    "        if detected_language in ['ru', 'kk']:\n",
    "            sentiment = rus_sentiment_classifier(text_to_analyze)[0]['label']\n",
    "        elif detected_language == 'en':\n",
    "            sentiment = en_sentiment_classifier(text_to_analyze)[0]['label']\n",
    "        \n",
    "        descriptive_labels = [\n",
    "         \"user asks a question for a telecommunications company\", \"user complains about a telecommunications company's service\",\n",
    "        \"user expresses gratitude to a telecommunications company\", \"user shares their opinion about a telecommunications company's service\"\n",
    "        ]\n",
    "        label_map = {\n",
    "            \"user asks a question for a telecommunications company\": \"question\",\n",
    "            \"user complains about a telecommunications company's service\": \"complaint\",\n",
    "            \"user expresses gratitude to a telecommunications company\": \"gratitude\",\n",
    "            \"user shares their opinion about a telecommunications company's service\": \"feedback\"\n",
    "        }\n",
    "        \n",
    "        type_result = zero_shot_classifier(text_to_analyze, descriptive_labels)\n",
    "        top_label = type_result['labels'][0]\n",
    "        comment_type = label_map.get(top_label, \"feedback\")\n",
    "\n",
    "    final_analysis = {\n",
    "        'text': comment_text,\n",
    "        'language': detected_language,\n",
    "        'moderation_verdict': moderation_verdict,\n",
    "        'sentiment': sentiment,\n",
    "        'comment_type': comment_type\n",
    "    }\n",
    "    return final_analysis\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    test_q = \"Подскажите, как сменить тариф?\"\n",
    "    test_g = \"Спасибо вам большое, все отлично работает!\"\n",
    "    test_c = \"Ужасный интернет, постоянно пропадает!\"\n",
    "    test_f = \"Пользуюсь уже год, в целом нормально.\"\n",
    "    test_spam = \"Заходи на мой канал про крипту www.example.com\"\n",
    "    test_kz = \"Керемет! Маған бәрі ұнады, рахмет сіздерге.\"\n",
    "    test_rus = \"Почему интернет так тупит?\"\n",
    "    \n",
    "    print(\"\\n--- Тестирование финального аналитического конвейера ---\")\n",
    "    print(f\"\\nВопрос: {analyze_comment(test_q)}\")\n",
    "    print(f\"Благодарность: {analyze_comment(test_g)}\")\n",
    "    print(f\"Жалоба: {analyze_comment(test_c)}\")\n",
    "    print(f\"Отзыв: {analyze_comment(test_f)}\")\n",
    "    print(f\"Спам: {analyze_comment(test_spam)}\")\n",
    "    print(f\"Казахский: {analyze_comment(test_kz)}\")\n",
    "    print(f\"Русский: {analyze_comment(test_rus)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc50d64-b480-4d46-abfe-8cd36c769adc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:dsfs]",
   "language": "python",
   "name": "conda-env-dsfs-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
